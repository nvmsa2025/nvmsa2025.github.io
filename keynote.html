<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Keynote Speeches</title>
    <style>
        hr {
            display: block;
            border: 1px solid #ccc; /* 원하는 색상과 두께로 변경 가능 */
            margin: 20px 0; /* 원하는 여백으로 변경 가능 */
        }

        .clearfix::after {
            content: "";
            clear: both;
            display: table;
        }

        .keynote {
            margin-bottom: 20px;
        }

        .col-lg-12 img {
            float: left;
            width: 30%;
            height: auto;
            margin-right: 15px;
            margin-top: 20px;
            margin-bottom: 10px;
        }

        .col-lg-12 {
            overflow: hidden; /* float 문제를 해결하기 위해 추가 */
        }

        @media (max-width: 768px) {
            .col-lg-12 img {
                float: none;
                width: 100%;
                margin: 10px 0;
            }
        }
    </style>
</head>
<body>
    <div>
        <div class="keynote clearfix">
            <div id="kn1">
                <div class="keynote-title">
                    <h2>Keynote Speech 1</h2>
                    <!-- <br> -->
                    <!-- <br> -->
                    <h3><b>Processing-in-Memory for Scalable AI: From Circuits to System-Level Co-Design</b> </h3>
                    <p><b>Speaker: <a href="https://ece.duke.edu/people/yiran-chen/">Yiran Chen</a></b>, Duke University</p>
                </div>
                <div class="col-lg-12">
                    <!-- <h3>Abstract:</h3> -->
                    <p>As artificial intelligence continues to push the boundaries of scale and complexity, memory systems have become a fundamental bottleneck in achieving efficient and scalable computation. Processing-in-Memory (PIM) has emerged as a compelling solution that shifts computation closer to where data resides to reduce energy, latency, and bandwidth demands. This talk revisits the evolution of PIM technologies developed in our group over the past decade. We will explore analog and digital PIM architectures based on ReRAM, SRAM, and CAM, highlighting their application to neural networks, transformers, graph analytics, and decision trees. Special emphasis will be placed on co-design strategies that bridge algorithm, architecture, and circuit-level considerations, including recent work on attention acceleration, CAM-based matching, sparsity exploitation, and training-aware robustness. Finally, the talk will discuss emerging directions (such as 3D-stacked PIM, hybrid analog-digital arrays, and software-defined PIM systems) that aim to realize practical, scalable, and domain-specific AI acceleration.</p>
                </div>
                <div class="col-lg-12">
                    <br>
                    <img class="img-responsive" src="img/keynote/chen_yiran_cropped.jpg" alt="Prof Chen Yiran">
                    <h3><strong>Speaker Bio</strong></h3>
                    <p>Yiran Chen is the John Cocke Distinguished Professor of Electrical and Computer Engineering at Duke University. He serves as the Principal Investigator and Director of the NSF AI Institute for Edge Computing Leveraging Next Generation Networks (Athena) and Co-Director of the Duke Center for Computational Evolutionary Intelligence (DCEI). His research group focuses on innovations in emerging memory and storage systems, machine learning and neuromorphic computing, and edge computing. Dr. Chen has authored over 600 publications and holds 96 U.S. patents. His work has received widespread recognition, including two Test-of-Time Awards and 14 Best Paper/Poster Awards. He is the recipient of the IEEE Circuits and Systems Society’s Charles A. Desoer Technical Achievement Award and the IEEE Computer Society’s Edward J. McCluskey Technical Achievement Award. He also serves as the inaugural Editor-in-Chief of the IEEE Transactions on Circuits and Systems for Artificial Intelligence (TCASAI) and the founding Chair of the IEEE Circuits and Systems Society’s Machine Learning Circuits and Systems (MLCAS) Technical Committee. He was the Editor-in-Chief of the IEEE Circuits and Systems Magazine between 2020-2023 and chaired the ACM Special Interest Group on Design Automation (SIGDA) between 2021-2024. He served as the Principal Investigator and Director of the NSF Industry–University Cooperative Research Center for Alternative Sustainable and Intelligent Computing (ASIC) between 2018-2025. Dr. Chen is a Fellow of the AAAS, ACM, IEEE, and NAI, and an ordinary member of the European Academy of Sciences and Arts.</p>
                </div>
            </div>
            <hr>
        </div>

        <div class="keynote clearfix">
            <div id="kn1">
                <div class="keynote-title">
                    <h2>Keynote Speech 2</h2>
                    <!-- <br> -->
                    <!-- <br> -->
                    <h3><b>Memory-Centric Computing: Enabling Fundamentally Efficient & Intelligent Machines</b> </h3>
                    <p><b>Speaker: <a href="https://people.inf.ethz.ch/omutlu/">Onur Mutlu</a></b>, ETH Zurich</p>
                </div>
                <div class="col-lg-12">
                    <!-- <h3>Abstract:</h3> -->
                    <p>Computing is bottlenecked by data. Large amounts of application data overwhelm the storage capability, communication capability, and computation capability of the modern machines we design today. As a result, many key applications' performance, efficiency, and scalability are bottlenecked by data movement. In this talk, we describe three major shortcomings of modern computers in terms of (1) dealing with data, (2) taking advantage of vast amounts of data, and (3) exploiting different semantic properties of application data. We argue that an intelligent computing architecture should be designed to handle data well. We posit that handling data well requires designing architectures based on three key principles: (1) data-centric, (2) data-driven, (3) data-aware. We give examples of how to exploit these principles to design a much more efficient and higher performance computing system. We especially discuss recent research that aims to fundamentally reduce memory latency and energy, and practically enable computation close to data, with at least two promising directions: (1) processing using memory, which exploits the fundamental operational properties of memory chips to perform massively-parallel computation in memory, with low-cost changes, (2) processing near memory, which integrates sophisticated additional processing capability in memory chips, the logic layer of 3D-stacked technologies, or memory controllers to enable near-memory computation with high memory bandwidth and low memory latency. We show both types of architectures can enable order(s) of magnitude improvements in performance and energy consumption of many important workloads, such as artificial intelligence, machine learning, graph analytics, database systems, video processing, climate modeling, genome analysis. We discuss how to enable adoption of such fundamentally more intelligent architectures, which are key to efficiency, performance, and sustainability. We conclude with some research opportunities in and guiding principles for future computing architecture and system designs. An accompanying overview of modern memory-centric computing ideas & systems can be found at <a href="https://arxiv.org/pdf/2012.03112">https://arxiv.org/pdf/2012.03112</a> ("A Modern Primer on Processing in Memory", updated February 2025).A shorter invited paper from IMW 2025 is at <a href="https://arxiv.org/pdf/2505.00458">https://arxiv.org/pdf/2505.00458</a> (“Memory-Centric Computing: Solving Computing’s Memory Problem”, May 2025)</p>
                </div>
                <div class="col-lg-12">
                    <br>
                    <img class="img-responsive" src="img/keynote/onur_mutlu.jpg" alt="Prof Onur Mutlu">
                    <h3><strong>Speaker Bio</strong></h3>
                    <p>Onur Mutlu is a Professor of Computer Science at ETH Zurich. He previously held the William D. and Nancy W. Strecker Early Career Professorship at Carnegie Mellon University. His current research interests are in computer architecture, computing systems, hardware security, memory & storage systems, and bioinformatics, with a major focus on designing fundamentally energy-efficient, high-performance, and robust computing systems. Many techniques he, with his group and collaborators, has invented over the years have largely influenced industry and have been widely employed in commercial microprocessors and memory & storage systems used daily by hundreds of millions of people. He obtained his PhD and MS in ECE from the University of Texas at Austin and BS degrees in Computer Engineering and Psychology from the University of Michigan, Ann Arbor. He started the Computer Architecture Group at Microsoft Research (2006-2009), and held product, research and visiting positions at Intel Corporation, Advanced Micro Devices, VMware, Google, and Stanford University. He received various honors for his research, including the 2025 IEEE Computer Society Harry H. Goode Memorial Award “for seminal contributions to computer architecture research and practice, especially in memory systems,” 2024 IFIP WG10.4 Jean-Claude Laprie Award in Dependable Computing (for the original RowHammer work), 2022 Persistent Impact Prize of the Non-Volatile Memory Systems Workshop (for original architectural work on Phase Change Memory), 2021 IEEE High Performance Computer Architecture Conference Test of Time Award (for the Runahead Execution work), 2025 IEEE/IFIP Dependable Systems and Networks Conference Test of Time Award, 2020 IEEE Computer Society Edward J. McCluskey Technical Achievement Award, 2019 ACM SIGARCH Maurice Wilkes Award and more than thirty best paper, “Top Pick” paper, or test-of-time recognitions at various leading computer systems, architecture, and security venues. He is an ACM Fellow, IEEE Fellow, and an elected member of the Academy of Europe. He enjoys teaching, mentoring, and enabling & democratizing access to high-quality research and education. He has supervised 24 PhD graduates, many of whom received major dissertation awards, 15 postdoctoral trainees, and more than 60 Master’s and Bachelor’s students. His computer architecture and digital logic design course lectures and materials are freely available on YouTube (<a href="https://www.youtube.com/OnurMutluLectures">https://www.youtube.com/OnurMutluLectures</a> & <a href="https://www.youtube.com/@CMUCompArch">https://www.youtube.com/@CMUCompArch</a>), and his research group (<a href="https://safari.ethz.ch/">https://safari.ethz.ch/</a>") makes a wide variety of open-source artifacts freely available online (<a href="https://github.com/CMU-SAFARI">https://github.com/CMU-SAFARI</a>). For more information, please see his webpage at <a href="https://people.inf.ethz.ch/omutlu/">https://people.inf.ethz.ch/omutlu/</a>. </p>
                </div>
            </div>
            <hr>
        </div>
    </div>

    <p>NVMSA'25 and RTCSA'25 will have joint keynotes. The keynote listed above is hosted by NVMSA. Information about the keynotes hosted by RTCSA can be found from: <a href=https://rtcsa2025.github.io/?page=keynote.html>https://rtcsa2025.github.io/?page=keynote.html</a> </p>
</body>
</html>